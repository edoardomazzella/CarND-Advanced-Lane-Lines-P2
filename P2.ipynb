{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "\n",
    "from helpers import np\n",
    "from helpers import glob\n",
    "from helpers import cv2\n",
    "from helpers import plt\n",
    "from helpers import mpimg\n",
    "from helpers import pickle\n",
    "from helpers import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calibrate the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrateCamera(imgpath, nx, ny, calibrationfile):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((ny*nx,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(imgpath)\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny),None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "            dist_pickle = {}\n",
    "            dist_pickle[\"objpoints\"] = objpoints\n",
    "            dist_pickle[\"imgpoints\"] = imgpoints\n",
    "            pickle.dump(dist_pickle, open(calibrationfile, \"wb\"))\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code\n",
    "calibrateCamera('camera_cal/calibration*.jpg', 9, 6, \"wide_dist_pickle.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undistort image function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistortImage(img, calibrationfile):\n",
    "    if(os.path.isfile(calibrationfile)):\n",
    "        # Read in the saved objpoints and imgpoints\n",
    "        dist_pickle = pickle.load(open(calibrationfile, \"rb\"))\n",
    "        objpoints = dist_pickle[\"objpoints\"]\n",
    "        imgpoints = dist_pickle[\"imgpoints\"]\n",
    "\n",
    "        # Do camera calibration given object points and image points\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "        # Undistort the image\n",
    "        undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    else:\n",
    "        undist = img\n",
    "\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code\n",
    "img = plt.imread('test_images/test1.jpg')\n",
    "undist = undistortImage(img, \"wide_dist_pickle.p\")\n",
    "plt.imshow(undist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get the perspective change matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPerspectiveMatrix():\n",
    "    # Define source and destination points\n",
    "    # Considered line is about 20m length and 3.7m width\n",
    "    src = np.float32([ [707, 462], [1043, 672], [275, 677], [578, 462] ])\n",
    "    # 720 px length = 20m, 800 px width = 3.7m \n",
    "    dst = np.float32([ [1040, 0], [1040, 719], [240, 719], [240, 0] ])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    # Get and return M\n",
    "    return M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code\n",
    "M, Minv = getPerspectiveMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding functions to be combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobelThreshold(img, orient = 'x', channel = 'R', sobel_kernel = 3, thresh = (0, 255)):\n",
    "    if channel == 'R':\n",
    "        img_channel = img[:,:,0]\n",
    "    elif channel == 'G':\n",
    "        img_channel = img[:,:,1]\n",
    "    elif channel == 'H':    \n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)    \n",
    "        img_channel = hls[:,:,0]    \n",
    "    elif channel == 'S':    \n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)    \n",
    "        img_channel = hls[:,:,2]\n",
    "    else:\n",
    "        img_channel = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img_channel, cv2.CV_64F, 1, 0, ksize = sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img_channel, cv2.CV_64F, 0, 1, ksize = sobel_kernel))\n",
    "\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "\n",
    "def magThreshold(img, channel = 'R', sobel_kernel = 3, thresh = (0, 255)):\n",
    "    if channel == 'R':\n",
    "        img_channel = img[:,:,0]\n",
    "    elif channel == 'G':\n",
    "        img_channel = img[:,:,1]\n",
    "    elif channel == 'H':    \n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)    \n",
    "        img_channel = hls[:,:,0]    \n",
    "    elif channel == 'S':    \n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)    \n",
    "        img_channel = hls[:,:,2]\n",
    "    else:\n",
    "        img_channel = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(img_channel, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(img_channel, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255\n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8)\n",
    "\n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= thresh[0]) & (gradmag <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "def dirThreshold(img, channel = 'R', sobel_kernel=3, thresh = (0, np.pi/2)):\n",
    "    if channel == 'R':\n",
    "        img_channel = img[:,:,0]\n",
    "    elif channel == 'G':\n",
    "        img_channel = img[:,:,1]\n",
    "    elif channel == 'H':    \n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)    \n",
    "        img_channel = hls[:,:,0]    \n",
    "    elif channel == 'S':    \n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)    \n",
    "        img_channel = hls[:,:,2]\n",
    "    else:\n",
    "        img_channel = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(img_channel, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(img_channel, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "\n",
    "    # Take the absolute value of the gradient direction,\n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code\n",
    "sx = sobelThreshold(undist, 'x', 'R', 9, thresh = (20, 100))\n",
    "sy = sobelThreshold(undist, 'y', 'R', 9, thresh = (20, 100))\n",
    "magthr = magThreshold(undist, 'R', 9, thresh = (30, 100))\n",
    "dirthr = dirThreshold(undist, 'R', 15, (0.7, 1.3))\n",
    "\n",
    "gr_binary = np.zeros_like(sx)\n",
    "gr_binary[((sx == 1) & (sy == 1)) | ((magthr == 1) & (dirthr == 1))] = 1\n",
    "\n",
    "plt.imshow(gr_binary, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_select(img):\n",
    "    LOW_WHITE = np.array([0, 0, 223], dtype=np.uint8)\n",
    "    HIGH_WHITE = np.array([90,63,255], dtype=np.uint8)\n",
    "    LOW_YELLOW = np.array([15,127,223], dtype=np.uint8)\n",
    "    HIGH_YELLOW = np.array([30,255,255], dtype=np.uint8)\n",
    "\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    wmask = cv2.inRange(hsv, LOW_WHITE, HIGH_WHITE)//255\n",
    "    ymask = cv2.inRange(hsv, LOW_YELLOW, HIGH_YELLOW)//255\n",
    "    binary_output = cv2.bitwise_or(ymask, wmask)\n",
    "    \n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code\n",
    "color_binary = color_select(undist)\n",
    "plt.imshow(color_binary, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the gradient and the color transformed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_binary = np.zeros_like(color_binary)\n",
    "combined_binary[(color_binary == 1) | (gr_binary == 1)] = 1\n",
    "\n",
    "plt.imshow(combined_binary, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code\n",
    "binary_warped = cv2.warpPerspective(combined_binary, M, (combined_binary.shape[1], combined_binary.shape[0]))\n",
    "plt.imshow(binary_warped, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane finder and polynomial fit functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the line and fit the polynomial of the first considered frame\n",
    "def findLines(binary_warped, nwindows = 9, margin = 100, minpix = 50, visualization = False):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Compute distance from the center of the lane\n",
    "    midlane = np.int(np.mean([leftx_base, rightx_base]))\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    left_fit, left_fitx, ploty = helpers.fit_poly(binary_warped.shape, leftx, lefty)\n",
    "    right_fit, right_fitx, ploty = helpers.fit_poly(binary_warped.shape, rightx, righty)\n",
    "    \n",
    "    left_curv = helpers.compute_curvature(binary_warped, leftx, lefty)\n",
    "    right_curv = helpers.compute_curvature(binary_warped, rightx, righty)\n",
    "    \n",
    "    xm_per_pix = 3.7 / 800\n",
    "    distance = (midpoint - midlane) * xm_per_pix\n",
    "    \n",
    "    # Visualization\n",
    "    if(visualization == True):\n",
    "        helpers.line_visualization(binary_warped, nonzerox, nonzeroy, left_lane_inds, right_lane_inds, left_fitx, right_fitx, ploty, margin)\n",
    "    \n",
    "    return left_fit, right_fit, left_fitx, right_fitx, ploty, left_curv, right_curv, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code\n",
    "left_fit, right_fit, left_fitx, right_fitx, ploty, left_curv, right_curv, distance = findLines(binary_warped, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curv = np.mean([left_curv, right_curv])\n",
    "\n",
    "# Example code\n",
    "result = helpers.drawLane(undist, binary_warped, ploty, left_fitx, right_fitx, curv, distance, Minv)\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneFinder():\n",
    "    def __init__(self):\n",
    "        self.__left_fit = []\n",
    "        self.__right_fit = []\n",
    "        self.__left_fitx = []\n",
    "        self.__right_fitx = []\n",
    "        self.__ploty = []\n",
    "        self.__left_curv = 0\n",
    "        self.__right_curv = 0\n",
    "        self.__distance = 0.0\n",
    "\n",
    "    def processImage(self, img):\n",
    "        # Undistort the image\n",
    "        undist = undistortImage(img, \"wide_dist_pickle.p\")\n",
    "\n",
    "        # Apply gradient thresholding\n",
    "        sx = sobelThreshold(undist, 'x', 'R', 9, thresh = (20, 100))\n",
    "        sy = sobelThreshold(undist, 'y', 'R', 9, thresh = (20, 100))\n",
    "        magthr = magThreshold(undist, 'R', 9, thresh = (30, 100))\n",
    "        dirthr = dirThreshold(undist, 'R', 15, (0.7, 1.3))\n",
    "\n",
    "        gr_binary = np.zeros_like(sx)\n",
    "        gr_binary[((sx == 1) & (sy == 1)) | ((magthr == 1) & (dirthr == 1))] = 1\n",
    "\n",
    "        # Apply color thresholding on S channel\n",
    "        color_binary = color_select(undist)\n",
    "\n",
    "        # Combine gradient and color thresholding\n",
    "        combined_binary = np.zeros_like(color_binary)\n",
    "        combined_binary[(color_binary == 1) | (gr_binary == 1)] = 1\n",
    "\n",
    "        # Warp image\n",
    "        binary_warped = cv2.warpPerspective(combined_binary, M, (combined_binary.shape[1], combined_binary.shape[0]))\n",
    "        \n",
    "        try:\n",
    "            self.__left_fit, self.__right_fit, self.__left_fitx, self.__right_fitx, self.__ploty, \\\n",
    "            self.__left_curv, self.__right_curv, self.__distance = findLines(binary_warped)\n",
    "        except:\n",
    "            print('undetected line')\n",
    "            \n",
    "        # Draw lane\n",
    "        curv = np.mean([self.__left_curv, self.__right_curv])\n",
    "        result = helpers.drawLane(undist, binary_warped, self.__ploty, self.__left_fitx, self.__right_fitx,\n",
    "                                  curv, self.__distance, Minv)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply pipeline on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = LaneFinder()\n",
    "\n",
    "input_folder = 'test_images/'\n",
    "output_folder = 'output_images/'\n",
    "\n",
    "for fname in os.listdir(input_folder):\n",
    "    # Read the image\n",
    "    img = plt.imread(input_folder + fname)\n",
    "    # Apply the pipeline\n",
    "    result = lf.processImage(img)\n",
    "    # Save the image\n",
    "    plt.imsave(output_folder + fname, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include libraries for videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the pipeline on project video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = LaneFinder()\n",
    "\n",
    "white_output = 'output_project_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(lf.processImage) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the pipeline on challenge video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = LaneFinder()\n",
    "\n",
    "white_output = 'output_challenge_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(lf.processImage) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the pipeline on harder challenge video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = LaneFinder()\n",
    "\n",
    "white_output = 'output_harder_challenge_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(lf.processImage) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
